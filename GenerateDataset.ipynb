{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "44dda083-9ba6-4c02-a813-eecad1577e48",
   "metadata": {},
   "source": [
    "# Dataset Generation\n",
    "# Normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4013fae2-e786-43c9-b6b2-af332d6bd14d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "\n",
    "\n",
    "def Normal_generate(n_samples, n_classes,feature_list):\n",
    "# Create datasets with different feature counts and 5 classes\n",
    "    for num_features in feature_list:\n",
    "      # Generate data with informative features\n",
    "        if n_classes * 2 > 2**num_features:\n",
    "            num_informative = n_classes + 1  # Adjust based on your needs\n",
    "        else:\n",
    "            num_informative = num_features\n",
    "        # Calculate minimum total features (considering redundant features)\n",
    "        min_features = num_informative + max(1, num_informative // 2)\n",
    "        \n",
    "        try:\n",
    "      # Generate data with informative features\n",
    "            X, y = make_classification(n_samples=n_samples, n_features=min_features, n_classes=n_classes, n_informative=num_informative,random_state=0)\n",
    "            Xfile_name=f\"./datasets/PCA_X_sample_{n_samples}_class_{n_classes}_feature_{min_features}\"\n",
    "            Yfile_name=f\"./datasets/PCA_Y_sample_{n_samples}_class_{n_classes}_feature_{min_features}\"\n",
    "\n",
    "            np.save(Xfile_name, X)\n",
    "            np.save(Yfile_name, y)\n",
    "            # Print information about the created dataset\n",
    "            print(f\"Dataset with {num_features} features and 5 classes:\")\n",
    "            print(f\"X shape: {X.shape}, y shape: {y.shape}\")\n",
    "        except Exception as e:\n",
    "            print(f\"{e}Error generating dataset with {num_features} features and {n_classes} classes.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c8625d9-b96b-48aa-9590-04722020e10b",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Noisy\n",
    "This code incorporates the following aspects:\n",
    "\n",
    "Feature and Class Generation: It uses make_classification to generate informative features for five classes with n_classes=5.\n",
    "Noise Addition: Gaussian noise with a specific scale (noise_scale) is introduced to each feature using np.random.normal. The noise is then added to the original features using element-wise addition (X + noise).\n",
    "Information Printing: It prints the shapes of the original (X) and noisy (X_noisy) datasets for verification.\n",
    "Explanation:\n",
    "\n",
    "The loop iterates through the desired feature counts (5, 10, 15, 20).\n",
    "The noise_scale parameter controls the amount of noise added to the features. Higher values introduce stronger noise.\n",
    "Additional Notes:\n",
    "\n",
    "You can explore different noise distributions like uniform noise using np.random.uniform for a wider range of noise characteristics.\n",
    "Consider using libraries like matplotlib or seaborn to visualize these datasets with noise. Techniques like histograms or density plots can help visualize the distribution of noise in each feature.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0b86e91-fae9-420f-ac65-95e04601c31e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# noise_scale = should be int\n",
    "def Noisy_generate(n_samples, n_classes,feature_list,  noise_scale):\n",
    "    noise_scale=noise_scale/100\n",
    "    # Create datasets with different feature counts, 5 classes, and noise\n",
    "    for num_features in feature_list:\n",
    "         # Generate data with informative features\n",
    "        if n_classes * 2 > 2**num_features:\n",
    "            num_informative = n_classes + 1  # Adjust based on your needs\n",
    "        else:\n",
    "            num_informative = num_features\n",
    "        \n",
    "        # Calculate minimum total features (considering redundant features)\n",
    "        min_features = num_informative + max(1, num_informative // 2)\n",
    "        try:\n",
    "          # Generate data with informative features\n",
    "            X, y = make_classification(n_samples=n_samples, n_features=min_features, n_classes=n_classes, n_informative=num_informative,random_state=0)\n",
    "\n",
    "            # Add Gaussian noise to each feature\n",
    "            noise = np.random.normal(scale=noise_scale, size=(X.shape[0], min_features))\n",
    "            X_noisy = X + noise\n",
    "            Xfile_name=f\"./datasets/PCA_Noisy_X_sample_{n_samples}_class_{n_classes}_feature_{min_features}_noise_scale_{noise_scale}_percent\"\n",
    "            Yfile_name=f\"./datasets/PCA_Noisy_Y_sample_{n_samples}_class_{n_classes}_feature_{min_features}_noise_scale_{noise_scale}_percent\"\n",
    "\n",
    "            np.save(Xfile_name,X_noisy)\n",
    "            np.save(Yfile_name, y)\n",
    "            # Print information about the created dataset\n",
    "            print(f\"Dataset with {num_features} features and 5 classes:\")\n",
    "            print(f\"X shape: {X.shape}, X_noisy shape: {X_noisy.shape}\")\n",
    "        except Exception as e:\n",
    "            print(f\"{e}Error generating dataset with {num_features} features and {n_classes} classes.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "305c06d3-97dd-427d-ab7c-733aa5c00a7b",
   "metadata": {},
   "source": [
    "# Outlier\n",
    "Feature Creation: It uses make_classification to generate informative features for three classes.\n",
    "Outlier Introduction:\n",
    "It calculates the number of outliers per class based on outlier_fraction. Then, it randomly selects indices from each class (using np.unique(y)) to introduce outliers.\n",
    "Outlier Scaling: The features at outlier indices are scaled by outlier_scale to create extreme values.\n",
    "Information Printing: It prints the shapes of the feature data (X) and class labels (y) for each dataset.\n",
    "Explanation:\n",
    "\n",
    "make_classification is better suited for datasets with multiple classes compared to make_blobs.\n",
    "The loop iterates through the desired feature counts (5, 10, 15, 20).\n",
    "np.unique(y) ensures outliers are introduced for all three classes.\n",
    "Consider using libraries like matplotlib or seaborn for visualizing these datasets with outliers.\n",
    "This code provides a foundation for creating datasets with controlled features, classes, and outliers for your machine learning experiments.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87638112-8305-42ed-a226-c75dea34db3d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#make outlier\n",
    "from sklearn.datasets import make_classification\n",
    "import numpy as np\n",
    "\n",
    "# # Define parameters\n",
    "# n_samples = 500\n",
    "# outlier_fraction shoulkd be int\n",
    "# outlier_scale = 5\n",
    "def Outlier_generate(n_samples, n_classes,feature_list,   outlier_fraction,outlier_scale):\n",
    "# Create datasets with different feature counts, 3 classes, and outliers\n",
    "    outlier_fraction =outlier_fraction/100\n",
    "    for num_features in feature_list:\n",
    "          # Generate data with informative features\n",
    "        if n_classes * 2 > 2**num_features:\n",
    "            num_informative = n_classes + 1  # Adjust based on your needs\n",
    "        else:\n",
    "            num_informative = num_features\n",
    "        \n",
    "        # Calculate minimum total features (considering redundant features)\n",
    "        min_features = num_informative + max(1, num_informative // 2)\n",
    "        try:\n",
    "            # Generate blobs with informative features\n",
    "            X, y = make_classification(n_samples=n_samples, n_features=min_features, n_classes=n_classes, n_informative=num_informative,random_state=0)\n",
    "\n",
    "            # Generate outlier indices for each class\n",
    "            num_outliers_per_class = int(n_samples * outlier_fraction / n_classes)\n",
    "            outlier_indices = []\n",
    "            for class_label in np.unique(y):\n",
    "                class_indices = np.where(y == class_label)[0]\n",
    "                outlier_indices.extend(np.random.choice(class_indices, num_outliers_per_class, replace=False))\n",
    "\n",
    "                # Scale outliers by a factor\n",
    "            X[outlier_indices] = X[outlier_indices] * outlier_scale\n",
    "            Xfile_name=f\"./datasets/PCA_Outlier_X_sample_{n_samples}_class_{n_classes}_feature_{min_features}_outlierfraction_{outlier_fraction}_percent_outlier_scale{outlier_scale}\"\n",
    "            Yfile_name=f\"./datasets/PCA_Outlier_Y_sample_{n_samples}_class_{n_classes}_feature_{min_features}_outlierfraction_{outlier_fraction}_percent_outlier_scale{outlier_scale}\"\n",
    "\n",
    "            np.save(Xfile_name, X)\n",
    "            np.save(Yfile_name, y)\n",
    "            # Print information about the created dataset\n",
    "            print(f\"Dataset with {num_features} features and 3 classes:\")\n",
    "            print(f\"X shape: {X.shape}, y shape: {y.shape}\")\n",
    "        except Exception as e:\n",
    "            print(f\"{e}Error generating dataset with {num_features} features and {n_classes} classes.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5264cfcf-c178-4901-8d14-ba1f858459b8",
   "metadata": {},
   "source": [
    "# Missing values\n",
    "This code incorporates the following aspects:\n",
    "\n",
    "Feature and Class Generation: It uses make_classification to generate informative features for five classes with n_classes=5.\n",
    "Missing Value Introduction: A boolean mask (missing_indices) is created using np.random.choice to randomly select elements where missing values will be introduced. The missing_ratio parameter controls the proportion of missing values.\n",
    "Missing Value Assignment: Elements at those indices in X are set to np.nan to represent missing values.\n",
    "Information Printing: It prints the shapes of the feature data (X) and class labels (y) for each dataset.\n",
    "Explanation:\n",
    "\n",
    "The loop iterates through the desired feature counts (5, 10, 15, 20).\n",
    "missing_ratio defines the percentage of missing values you want to introduce in each dataset. Adjust this value as needed.\n",
    "Additional Notes:\n",
    "\n",
    "This code assumes you want missing values to be randomly distributed across all features. You can modify the code to introduce them in specific features or patterns if desired.\n",
    "Consider using libraries like pandas.DataFrame to represent the data with missing values. This allows for easier handling and exploration of missing data using pandas functionalities.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef05944d-070e-44c7-91be-af98566fe75d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "import numpy as np\n",
    "\n",
    "# Define parameters\n",
    "# n_samples = 500\n",
    "# missing_ratio = 0.1  # Adjust for desired proportion of missing values\n",
    "def Missingvalue_generate(n_samples, n_classes,feature_list,   missing_ratio, save=False):\n",
    "    missing_ratio_str=missing_ratio\n",
    "    missing_ratio =missing_ratio/100\n",
    "    # Create datasets with different feature counts, 5 classes, and missing values\n",
    "    for num_features in feature_list:\n",
    "        # Generate data with informative features\n",
    "        if n_classes * 2 > 2**num_features:\n",
    "            num_informative = n_classes + 1  # Adjust based on your needs\n",
    "        else:\n",
    "            num_informative = num_features\n",
    "        \n",
    "        # Calculate minimum total features (considering redundant features)\n",
    "        min_features = num_informative + max(1, num_informative // 2)\n",
    "        \n",
    "        try:\n",
    "            X, y = make_classification(n_samples=n_samples, n_features=min_features, n_classes=n_classes, n_informative=num_informative,random_state=0)\n",
    "\n",
    "            # Introduce missing values randomly\n",
    "            missing_indices = np.random.choice([True, False], size=(n_samples, min_features), p=[missing_ratio, 1-missing_ratio])\n",
    "            X[missing_indices] = np.nan\n",
    "            Xfile_name=f\"./datasets/PCA_Missing_X_sample_{n_samples}_class_{n_classes}_feature_{min_features}_missratio_{missing_ratio_str}_percent\"\n",
    "            Yfile_name=f\"./datasets/PCA_Missing_Y_sample_{n_samples}_class_{n_classes}_feature_{min_features}_missratio_{missing_ratio_str}_percent\"\n",
    "\n",
    "            np.save(Xfile_name, X)\n",
    "            np.save(Yfile_name, y)\n",
    "            # Print information about the created dataset\n",
    "            print(f\"Dataset with {num_features} features and 5 classes:\")\n",
    "            print(f\"X shape: {X.shape}, y shape: {y.shape}\")\n",
    "        except Exception as e:\n",
    "            print(f\"{e}Error generating dataset with {num_features} features and {n_classes} classes.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75f93f21-d148-4252-9e83-56bf0c0d11f1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# how use\n",
    "for nsample in [100,500]:#number of samples\n",
    "    for nclass in [3,5]: #classes\n",
    "        Normal_generate(nsample, nclass,feature_list=[3,5,10,15,20])\n",
    "        #Noisy_generate(nsample, nclass,feature_list=[3,5,10,15,20],  noise_scale=50)\n",
    "        #Outlier_generate(nsample, nclass,feature_list=[3,5,10,15,20],   outlier_fraction=10,outlier_scale=5)\n",
    "        #Missingvalue_generate(n_samples=nsample, n_classes=nclass,feature_list=[3,5,10,15,20],   missing_ratio=10, save=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c6156e8-e1df-4ca6-9a9b-a0aef2d912fe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
